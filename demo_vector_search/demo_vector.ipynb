{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415a6d6d-7eed-4f84-ba47-08cab6b90a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510dda4b-7403-46f2-a865-a9a836f1cf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar as bibliotecas necessárias\n",
    "from google.cloud.aiplatform.matching_engine import MatchingEngineIndex\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import storage\n",
    "from datetime import datetime\n",
    "import json\n",
    "import uuid\n",
    "import re\n",
    "import os\n",
    "\n",
    "PROJECT_ID = 'estudo-ia-449223'\n",
    "LOCATION = 'us-central1'\n",
    "uid = str(uuid.uuid4())[:5]\n",
    "\n",
    "PROCESSING_BUCKET_NAME = 'demo-bucket-rag'\n",
    "INDEX = f'demo-rag-product-embs_{uid}'\n",
    "INDEX_ENDPOINT = f'demo-rag-product-embs-endpoint_{uid}'\n",
    "INDEX_ENDPOINT_DEPLOYED = f'demo_rag_product_embs_deployed_{uid}'\n",
    "embed_file_path = f'demo-embeddings_{uid}.json'\n",
    "sentence_file_path = f'demo-sentences_{uid}.json'\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)\n",
    "storage_client = storage.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ea9cee-3e70-4946-bfe8-e7f59517a495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    cleaned_text = re.sub(r\"\\u2022\", \"\", text) # Remove bullet points\n",
    "    return re.sub(r\"\\s+\", \" \", cleaned_text).strip() # Remove espaços extras\n",
    "\n",
    "def generate_txt_embeddings(sentences):\n",
    "    model = TextEmbeddingModel.from_pretrained('text-embedding-004')\n",
    "    embeddings = model.get_embeddings(sentences)\n",
    "    return [embedding.values for embedding in embeddings]\n",
    "\n",
    "def upload_file(bucket_name, file_path):\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(os.path.basename(file_path))\n",
    "    blob.upload_from_filename(file_path)\n",
    "\n",
    "def save_embeddings(sentences, embeddings):\n",
    "    with open(embed_file_path, \"w\") as embed_file, open(sentence_file_path, \"w\") as sentence_file:\n",
    "        for sentence, embedding in zip(sentences, embeddings):\n",
    "            json.dump({\"id\": uid, \"embedding\": embedding}, embed_file)\n",
    "            embed_file.write(\"\\n\")\n",
    "            json.dump({\"id\": uid, \"sentence\": clean_text(sentence)}, sentence_file)\n",
    "            sentence_file.write(\"\\n\")\n",
    "    print(f\"Arquivos {embed_file_path} e {sentence_file_path} salvos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee4a5a5-d7fd-4606-9dd0-f87dda167af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['o itau gosta de openmetadata', 'o bradesco gosta de astrix', 'o unibanco gosta de goiaba', 'o nubank gosta de abobora']\n",
    "embeddings = generate_txt_embeddings(sentences)\n",
    "\n",
    "save_embeddings(sentences, embeddings)\n",
    "\n",
    "upload_file(PROCESSING_BUCKET_NAME, embed_file_path)\n",
    "upload_file(PROCESSING_BUCKET_NAME, sentence_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db00b8e3-9899-4a9c-adb9-7fc67b1c113e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cria o index\n",
    "my_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
    "    display_name = INDEX,\n",
    "    contents_delta_uri = f\"gs://{PROCESSING_BUCKET_NAME}/{embed_file_path}\",\n",
    "    dimensions = 768,\n",
    "    approximate_neighbors_count = 10,\n",
    "    project=PROJECT_ID,\n",
    "    location=LOCATION\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4935db05-405c-4425-aefe-f2d1233f5258",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cria o endpoint\n",
    "my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
    "    display_name = INDEX_ENDPOINT,\n",
    "    public_endpoint_enabled = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686c7b5d-4f93-427e-ade4-f0a33053d975",
   "metadata": {},
   "outputs": [],
   "source": [
    "inicio = datetime.now()\n",
    "\n",
    "# cria o deploy\n",
    "my_index_endpoint.deploy_index(\n",
    "    index = my_index, deployed_index_id = INDEX_ENDPOINT_DEPLOYED\n",
    ")\n",
    "\n",
    "print(f\"{round((datetime.now() - inicio).total_seconds() / 60, 2)} minutos.\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m127",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m127"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
